{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3d50160-a52d-45ee-83e3-eeac76c291dc",
   "metadata": {},
   "source": [
    "### SPI "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19669c06-4e6a-4794-9d6c-166b24eb6e9d",
   "metadata": {},
   "source": [
    "#### data split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a35d9bd0-3d41-4536-8907-97105300a7cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path = '../data/spi10_2nrs.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff57c28-de94-499c-b6c7-7a2994c66c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import nrs2class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e35c5658-854a-4bbd-a45e-8b85e5e244af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.pacu_nrs = df.pacu_nrs.map(lambda x: nrs2class(x,pain_type=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe596b20-5a07-410f-9605-6be70e38f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "xtr, xte, ytr, yte = train_test_split(df.iloc[:,:-1], df.iloc[:,-1], test_size=0.4, shuffle=True, stratify=df.iloc[:,-1], random_state=34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9bea85b-b234-4cd2-a6b0-3047c5c8b640",
   "metadata": {},
   "outputs": [],
   "source": [
    "trdf = xtr.join(ytr)\n",
    "tedf = xte.join(yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b8b7e2d-dff8-4aea-83d3-fe87264d0ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trdf.to_csv('../data/spi10_nrs_train.csv',index=False)\n",
    "tedf.to_csv('../data/spi10_nrs_test.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be1be534-1677-4181-904b-613baf6229dc",
   "metadata": {},
   "source": [
    "#### Model shooting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc18d806-4190-4d24-8649-542d6889222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from dataset import Spi10_2nrs\n",
    "\n",
    "trdt  = Spi10_2nrs('../data/spi10_nrs_train.csv')\n",
    "tedt  = Spi10_2nrs('../data/spi10_nrs_test.csv')\n",
    "\n",
    "trdl  = torch.utils.data.DataLoader(trdt, batch_size=8)\n",
    "tedl  = torch.utils.data.DataLoader(tedt, batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "469d9ba8-2ae8-481d-a3c4-66371b5fbca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "trit = iter(trdl)\n",
    "\n",
    "x,y = next(trit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b633ea1d-2017-4c5c-a947-18592b1be7db",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-0ef93e919d19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0min_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlin_0\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_node\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0min_node\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mgelu_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGELU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mbn_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBatchNorm1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "in_node = 5\n",
    "lin_0  = nn.Linear(in_node,in_node*2)\n",
    "gelu_0 = nn.GELU()\n",
    "bn_0 = nn.BatchNorm1d(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3ba803-ff06-4399-84d1-ed689f244cd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdfbc5f-c279-4edb-b6c9-215e9d9c5f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torchaudio\n",
    "class SimpleSPI10(torch.nn.Module):\n",
    "    def __init__(self,in_node=5):\n",
    "        super(SimpleSPI10,self).__init__()\n",
    "\n",
    "        # feature_extraction\n",
    "        bundle = torchaudio.pipelines.WAV2VEC2_ASR_BASE_960H\n",
    "        self.wave2vec = bundle.get_model()\n",
    "    \n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=32, nhead=4)\n",
    "        tf_enc = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "\n",
    "\n",
    "        conv1d_0 = nn.Conv1d(281,140,3)\n",
    "        gelu_0 = nn.GELU()\n",
    "        bn_0 = nn.BatchNorm1d(140)\n",
    "        convb_0 = nn.Sequential(conv1d_0,gelu_0,bn_0)\n",
    "\n",
    "        conv1d_1 = nn.Conv1d(140,70,3)\n",
    "        gelu_1 = nn.GELU()\n",
    "        bn_1 = nn.BatchNorm1d(70)\n",
    "        convb_1 = nn.Sequential(conv1d_1,gelu_1,bn_1)\n",
    "\n",
    "        conv1d_2 = nn.Conv1d(70,35,3)\n",
    "        gelu_2 = nn.GELU()\n",
    "        bn_2 = nn.BatchNorm1d(35)\n",
    "        convb_2 = nn.Sequential(conv1d_2,gelu_2,bn_2)\n",
    "\n",
    "        lin_3 = nn.Linear(26,14)\n",
    "        relu_3 = nn.ReLU()\n",
    "        linb_0 = nn.Sequential(lin_3,relu_3)\n",
    "\n",
    "        lin_4 = nn.Linear(14,7)\n",
    "        relu_4 = nn.ReLU()\n",
    "        bn_4 = nn.BatchNorm1d(35)\n",
    "        linb_1 = nn.Sequential(lin_4,relu_4,bn_4)\n",
    "\n",
    "        fl_5 = nn.Flatten()\n",
    "        lin_5 = nn.Linear(245,2)\n",
    "\n",
    "        final = nn.Sequential(fl_5,lin_5)\n",
    "        convbs = nn.Sequential(convb_0,convb_1,convb_2)\n",
    "        lins   = nn.Sequential(linb_0,linb_1)\n",
    "\n",
    "        self.blocks = nn.ModuleDict({'attention':tf_enc,'conv_blocks':convbs,'lin_blocks':lins,'fc':final})\n",
    "        \n",
    "    def forward(self,out):\n",
    "        out, _ = self.wave2vec(out)\n",
    "        out    = self.blocks['attention'](out)\n",
    "        out    = self.blocks['conv_blocks'](out)\n",
    "        out    = self.blocks['lin_blocks'](out)\n",
    "        out    = self.blocks['fc'](out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf04320c-72a2-44a8-9ec9-a689ec541f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "con0 = cons().to(device)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "opt  = torch.optim.Adam(con0.parameters() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7c32ed-6e90-49fd-8541-f28b79487fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dl,model,lossf,opt):\n",
    "    for x,y in dl:\n",
    "        x,y = x.to(device),y.to(device)\n",
    "        pre = model(x)\n",
    "        loss = lossf(pre,y)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "def test(dl,model,lossf):\n",
    "    model.eval()\n",
    "    size, acc , losses = len(dl.dataset) ,0,0\n",
    "    with torch.no_grad():\n",
    "        for x,y in dl:\n",
    "            x,y = x.to(device),y.to(device)\n",
    "            pre = model(x)\n",
    "            loss = lossf(pre,y)\n",
    "\n",
    "            acc += (pre.argmax(1)==y).type(torch.float).sum().item()\n",
    "            losses += loss.item()\n",
    "    print(f'{acc/size} : {losses/size}')\n",
    "\n",
    "from tqdm import tqdm\n",
    "for _ in range(120):\n",
    "    train(trdl,con0,loss,opt)\n",
    "    test(tedl,con0,loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch0",
   "language": "python",
   "name": "torch0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
